{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Template Notebook - v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should serve as a template for the standard modelling we will all be using for as the base of version 1 development.\n",
    "\n",
    "The goal is for us to use the same predicted probabilities and classes to build different functions according the to tasks assigned to us.\n",
    "\n",
    "The notebook should be used as follows:\n",
    "1. Import all needed packages:\n",
    "2. Load Data\n",
    "3. Split Train and Test Sets\n",
    "4. Build and Run model\n",
    "5. Output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the case a Module Not Found error is thrown, it will automatically attempt to install all needed packages. You would have to rerun the import package cell again after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    !pip install pandas\n",
    "    !pip install numpy\n",
    "    !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import datasets\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    from sklearn.metrics import precision_score, precision_recall_curve\n",
    "    print('import successful')\n",
    "except ModuleNotFoundError:\n",
    "    print('forcing install of necessary packages. If you see this, rerun this cell to try again')\n",
    "    install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're starting off with is the standard breast cancer dataset that lends itself directly to binary classification modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the simplest flavour of the ordinary least squares logistic regression in this case and no data transformation / scaling to maintain simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobel\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides the basic outputs we will be using for function building as variables. They are as follows:\n",
    "1. predicted_probabilities: this is output of pre for which we will be performing optizations. This has two 'columns' where the values in index 0 are the probabilities for the class 0 and those in index 1 have probabilies for class 1\n",
    "2. sklearn_class_labels: this is the class label prediction computed by sklearn's density function\n",
    "3. naive_class_labels: this is the class label prediction computed by using a naïve 0.5 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predicted probabilties: (188, 2)\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = clf.predict_proba(X_test)\n",
    "print('shape of predicted probabilties:', predicted_probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of model default class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "sklearn_class_labels = clf.predict(X_test)\n",
    "print('shape of model default class predicttions:', sklearn_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of naïve class predicttions: (188,)\n"
     ]
    }
   ],
   "source": [
    "naive_class_labels = np.where(predicted_probabilities[:,1] > 0.5, 1, 0)\n",
    "print('shape of naïve class predicttions:', naive_class_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and F1 score of sklearn predicted classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9680851063829787, 0.9752066115702479)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy and F1 score of sklearn predicted classes')\n",
    "accuracy_score(sklearn_class_labels, y_test), f1_score(sklearn_class_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and F1 score of naive predicted classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9680851063829787, 0.9752066115702479)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy and F1 score of naive predicted classes')\n",
    "accuracy_score(naive_class_labels, y_test), f1_score(naive_class_labels, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_probs(model,X_test):\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    return y_scores\n",
    "\n",
    "def adjusted_classes(y_scores, t):\n",
    "##works for binary classes right now\n",
    "    return [1 if y >= t else 0 for y in y_scores]\n",
    "\n",
    "def find_best_scores(numtimes, y_scores):\n",
    "    best = 0\n",
    "    increment = 1/numtimes\n",
    "    #threshold = increment\n",
    "    for threshold in np.arange(0.0, 1.0, 0.1):\n",
    "        y_pred_adjusted = adjusted_classes(y_scores, threshold)\n",
    "        score = precision_score(y_pred_adjusted, y_test)\n",
    "        if score >= best:\n",
    "            best = score\n",
    "    return best, threshold\n",
    "\n",
    "#best threshold and precision score\n",
    "def find_best_threshold(model, X_test, numtimes):\n",
    "    y_scores = getting_probs(model,X_test)\n",
    "    return find_best_scores(numtimes,y_scores)\n",
    "\n",
    "#labels with best threshold\n",
    "def best_threshold_labels(model, X_test, numtimes):\n",
    "    y_scores = getting_probs(model,X_test)\n",
    "    res = find_best_scores(numtimes, y_scores)\n",
    "    return adjusted_classes(y_scores, res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
